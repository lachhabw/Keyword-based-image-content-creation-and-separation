{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should install some libraries:\n",
    "+ tensorflow, numpy, matplotlib, tqdm, transformers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import keras.backend as K\n",
    "from tqdm import tqdm\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to draw images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(image_list, k=3, cmap='gray'):\n",
    "\n",
    "    n = len(image_list)\n",
    "    if n > 0:\n",
    "        nrows = (n-1)//k+1\n",
    "        fig1, plots1 = plt.subplots(figsize=(5*k, 5*nrows), nrows=nrows, ncols=k)\n",
    "\n",
    "        if nrows > 1:\n",
    "            for i in range(nrows):\n",
    "                for j in range(k):\n",
    "                    index = k*i+j\n",
    "                    if index < n:\n",
    "                        plots1[i, j].imshow(image_list[index], cmap=cmap)\n",
    "        else:\n",
    "            for j in range((n-1)%k+1):\n",
    "                plots1[j].imshow(image_list[j], cmap=cmap)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1). Cifar10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1) Diffusion Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup Diffusion functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1000\n",
    "beta_0 = 1e-4\n",
    "beta_T = 0.02\n",
    "\n",
    "betas = tf.linspace(start=beta_0, stop=beta_T, num=T)\n",
    "alphas = 1.0 - betas\n",
    "alpha_cum = K.cast(np.cumprod(alphas), \"float32\")\n",
    "alpha_cum = tf.concat((alpha_cum, [1.0]), axis=0) # for alpha_0=1.0\n",
    "\n",
    "def forward_diffusion(x_0, t):\n",
    "    epsilon = tf.random.normal(shape=tf.shape(x_0))\n",
    "    alpha_cum_t = K.gather(alpha_cum, t)\n",
    "    alpha_cum_t = K.reshape(alpha_cum_t, (-1, 1, 1, 1))\n",
    "    x_t = (alpha_cum_t**0.5)*x_0 + ((1-alpha_cum_t)**0.5)*epsilon\n",
    "    return x_t, epsilon\n",
    "\n",
    "def denoise(model, x, y, T, n_steps=50, nu=0.5):\n",
    "    # prepare steps\n",
    "    n = tf.shape(x)[0]\n",
    "    to = list(range(0, T, T//n_steps))\n",
    "    to.append(-1) # for alpha_cum_0=1.0\n",
    "    # Sampling\n",
    "    for i in tqdm(list(reversed(range(len(to)-1)))):\n",
    "        # Get time\n",
    "        t = tf.repeat(to[i], n)\n",
    "        # Predict the noise\n",
    "        predicted_noise = model([x, t, y], training=False)\n",
    "        # Sample a noise\n",
    "        noise = tf.random.normal(shape=(tf.shape(x)))\n",
    "        # Calculate the std\n",
    "        sigma = nu*((1-alpha_cum[to[i-1]])/(1-alpha_cum[to[i]]))**0.5*(1-alpha_cum[to[i]]/alpha_cum[to[i-1]])**0.5\n",
    "        # Get the predicted x0\n",
    "        predicted_x0 = (x-(1-alpha_cum[to[i]])**0.5*predicted_noise)/alpha_cum[to[i]]**0.5\n",
    "        #predicted_x0 /= np.quantile(np.abs(predicted_x0), 0.99, axis=[1, 2, 3], keepdims=True)\n",
    "        #predicted_x0 = tf.clip_by_value(predicted_x0, -1, 1)\n",
    "        # Calculate direction pointing to x_t\n",
    "        direction = (1-alpha_cum[to[i-1]]-sigma**2)**0.5 * predicted_noise\n",
    "        # Get x_t-1\n",
    "        x = alpha_cum[to[i-1]]**0.5 * predicted_x0 + direction + sigma*noise\n",
    "    # Clip to the range\n",
    "    x = tf.clip_by_value(x, -1.0, 1.0)*0.5+0.5\n",
    "    return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load unet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = tf.keras.models.load_model(\"./models/unet_1000_cifar_cond\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = tf.repeat(tf.range(10), 10) # 10 elements from each of the 10 classes\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.normal(shape=(100, 32, 32, 3)) # random latent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch the generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpm_imgs = denoise(model=unet, x=x, T=T, y=label, n_steps=50) # 50 gives good results, and faster than 1000 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw(ddpm_imgs, k=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2) GANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = tf.keras.models.load_model(\"./models/ccifar_gan_200/\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = tf.repeat(tf.range(10), 10) # 10 elements from each of the 10 classes\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent = tf.random.normal(shape=(100, 128)) # random latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_imgs = gan.predict([latent, label])*0.5+0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw(fake_imgs, k=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2). CUB-200"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Text model: CLIP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it did not load properly, restart the notebook, import libraries, and execute it (without importing previous models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoProcessor, TFCLIPModel\n",
    "\n",
    "clip = TFCLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = AutoProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(text):\n",
    "    tokens = tokenizer([text,  \". \"*23], padding=True, return_tensors=\"tf\")[\"input_ids\"][:1]\n",
    "    inputs_text = {\"input_ids\": tokens}\n",
    "    inputs_text[\"pixel_values\"] = np.zeros(shape=(1, 3, 224, 224))\n",
    "    out = clip(inputs_text)\n",
    "    embeddings = tf.concat((out[\"text_model_output\"][\"pooler_output\"][:, None, :], out[\"text_model_output\"][\"last_hidden_state\"]), axis=1)\n",
    "    return embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GANs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = tf.keras.models.load_model(\"./models/attngan_350/\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"a red bird, high resolution, high quality\"\n",
    "k = 5 # 5 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_be_visualised = tf.random.normal(shape=(k, 100))\n",
    "prompt = tf.repeat(get_embeddings(text), k, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, _, weights = gan.predict([to_be_visualised, prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw(imgs*0.5+0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ok",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
